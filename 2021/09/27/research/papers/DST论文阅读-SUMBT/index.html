<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>DST论文阅读-SUMBT | Curious;的个人划水博客</title>
  <meta name="description" content="" />
  <meta name="keywords" content="" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="shortcut icon" href="/">
  <link rel="alternate" href="/atom.xml" title="Curious;的个人划水博客" type="application/atom+xml">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="SUMBT: Slot-Utterance Matching for Universal and Scalable Belief Tracking论文阅读笔记SUMBT: 槽-话语匹配的对话状态跟踪器，用来进行通用和可扩展的信念跟踪">
<meta property="og:type" content="article">
<meta property="og:title" content="DST论文阅读-SUMBT">
<meta property="og:url" content="http://example.com/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/index.html">
<meta property="og:site_name" content="Curious;的个人划水博客">
<meta property="og:description" content="SUMBT: Slot-Utterance Matching for Universal and Scalable Belief Tracking论文阅读笔记SUMBT: 槽-话语匹配的对话状态跟踪器，用来进行通用和可扩展的信念跟踪">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-27-12-06-39.png">
<meta property="og:image" content="http://example.com/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-28-17-32-41.png">
<meta property="og:image" content="http://example.com/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-28-19-27-17.png">
<meta property="og:image" content="http://example.com/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-28-19-46-31.png">
<meta property="article:published_time" content="2021-09-27T01:46:05.000Z">
<meta property="article:modified_time" content="2022-11-20T01:50:08.929Z">
<meta property="article:author" content="Curious;">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="Dialogue State Tracking">
<meta property="article:tag" content="论文笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-27-12-06-39.png">
    
  <link href="https://fonts.googleapis.com/css?family=Inconsolata|Titillium+Web" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">
  <link href='//cdn.bootcss.com/node-waves/0.7.5/waves.min.css' rel='stylesheet'>
  
<link rel="stylesheet" href="/style.css">

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="loading-bar-wrapper">
  <div id="loading-bar"></div>
</div>


  <script>setLoadingBarProgress(20)</script> 
  <header class="l_header">
	<div class='wrapper'>
		<div class="nav-main container container--flex">
			<a class="logo flat-box" href='/' >
				Curious;的个人划水博客
			</a>
			<div class='menu'>
				<ul class='h-list'>
					
						<li>
							<a class='flat-box nav-home' href='/'>
								Home
							</a>
						</li>
					
						<li>
							<a class='flat-box nav-archives' href='/archives'>
								Archives
							</a>
						</li>
					
						<li>
							<a class='flat-box nav-gallery' target="_blank" rel="noopener" href='https://photos.google.com/album/AF1QipNoqKYgspQo5O1YhlFXGCQ7p575KBH3Yxf8WHL4?hl=zh-CN'>
								Gallery
							</a>
						</li>
					
						<li>
							<a class='flat-box nav-about' href='/about'>
								About
							</a>
						</li>
					
				</ul>
				<div class='underline'></div>
			</div>
			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="Search" />
						<span class="icon icon-search"></span>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a href='javascript:void(0)'><span class="icon icon-search flat-box"></span></a></li>
				
				<li class='s-menu'><a href='javascript:void(0)'><span class="icon icon-menu flat-box"></span></a></li>
			</ul>
		</div>
		
		<div class='nav-sub container container--flex'>
			<a class="logo" class="flat-box" href='javascript:void(0)'>
				Word of Forks
			</a>

			<ul class='switcher h-list'>
				<li class='s-comment'><a href='javascript:void(0)'><span class="icon icon-chat_bubble_outline flat-box"></span></a></li>
				<li class='s-top'><a href='javascript:void(0)'><span class="icon icon-arrow_upward flat-box"></span></a></li>
				<li class='s-toc'><a href='javascript:void(0)'><span class="icon icon-format_list_numbered flat-box"></span></a></li>
			</ul>
		</div>
	</div>
</header>
<aside class="menu-phone">
	<nav>
		
			<a href="/" class="nav-home nav">
				Home
			</a>
		
			<a href="/archives" class="nav-archives nav">
				Archives
			</a>
		
			<a target="_blank" rel="noopener" href="https://photos.google.com/album/AF1QipNoqKYgspQo5O1YhlFXGCQ7p575KBH3Yxf8WHL4?hl=zh-CN" class="nav-gallery nav">
				Gallery
			</a>
		
			<a href="/about" class="nav-about nav">
				About
			</a>
		
	</nav>
</aside>

    <script>setLoadingBarProgress(40);</script>
  <div class="l_body">
    <div class='container clearfix'>
      <div class='l_main'>
        <article id="post-research/papers/DST论文阅读-SUMBT"
  class="post white-box article-type-post"
  itemscope itemprop="blogPost">
	<section class='meta'>
	<h2 class="title">
  	<a href="/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/">
    	DST论文阅读-SUMBT
    </a>
  </h2>
	<time>
	  9月 27, 2021
	</time>
	
    
    <div class='cats'>
        <a href="/categories/NLP/">NLP</a>
    </div>

	</section>
	
		<section class="toc-wrapper"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E7%9A%84%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%E8%A1%A5%E5%85%85"><span class="toc-number">1.</span> <span class="toc-text">一些基础概念的个人笔记补充</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5"><span class="toc-number">1.2.</span> <span class="toc-text">关键概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">1.3.</span> <span class="toc-text">评价指标</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-number">2.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-number">3.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SUMBT"><span class="toc-number">4.</span> <span class="toc-text">SUMBT</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Contextual-Semantic-Encoders"><span class="toc-number">4.1.</span> <span class="toc-text">Contextual Semantic Encoders</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Slot-Utterance-Matching"><span class="toc-number">4.2.</span> <span class="toc-text">Slot-Utterance Matching</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Belief-Tracker-%E5%AF%B9%E8%AF%9D%E7%8A%B6%E6%80%81%E8%B7%9F%E8%B8%AA%E5%99%A8"><span class="toc-number">4.3.</span> <span class="toc-text">Belief Tracker 对话状态跟踪器</span></a></li></ol></li></ol></section>
	
	<section class="article typo">
  	<div class="article-entry" itemprop="articleBody">
    	<p>SUMBT: Slot-Utterance Matching for Universal and Scalable Belief Tracking论文阅读笔记<br>SUMBT: 槽-话语匹配的对话状态跟踪器，用来进行通用和可扩展的信念跟踪</p>
<span id="more"></span>

<p>References:</p>
<blockquote>
<p>Lee H, Lee J, Kim T Y. SUMBT: Slot-Utterance Matching for Universal and Scalable Belief Tracking[C]//Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019: 5478-5483.<br>对话状态跟踪学习笔记：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zerozzl01/article/details/112215175">https://blog.csdn.net/zerozzl01/article/details/112215175</a></p>
</blockquote>
<p>注：分段和作者的文章不一定相同</p>
<h1 id="一些基础概念的个人笔记补充"><a href="#一些基础概念的个人笔记补充" class="headerlink" title="一些基础概念的个人笔记补充"></a>一些基础概念的个人笔记补充</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>对话状态跟踪（dialogue state tracking）是任务型（task-oriented）对话系统中的一部分。更具体的来说，是对话管理中的一部分。对话状态是从对话开始到当前对话的用户目标的总结，通常表现为多组槽-值（slot-value）的组合的形式，有时也会包括对话所属的领域、用户意图等信息。对话状态跟踪是指结合对话历史、当前对话、前一轮对话状态等信息，推断并更新当前对话状态的过程</p>
<h2 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h2><p>1）领域（domain）：可以理解为业务场景，如hotel、train、restaurant等。<br>2）意图（intention）：用户话语的目的，如请求信息、提供信息、确认信息等。<br>3）槽（slot）：槽指某种信息，与完成任务所需要获得的某种信息相对应。比如在预定酒店这个任务中，相关的槽有name、area、price range等。餐馆示例：[area, food, price range]<br>4）本体（ontology）：数据集中，涉及到的所有领域、意图、槽以及相关的所有值构成的数据字典，称为该数据集的本体。</p>
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><p>1）联合目标准确率（joint goal accuracy）/ 联合状态准确率（joint state accuracy）：一般也简称joint accuracy。对于每轮对话，将预测的对话状态和真实的对话状态进行比较，当且仅当对话状态中所有的（domain，slot，value）预测正确时，才认为对话状态预测正确。<br><font color="red"><br>问题记录：<br>这里需要结合论文所给出的代码查看下联合目标准确率的具体含义，到底是不是一次对话过程中，全部状态正确才算正确？<br></font></p>
<p>2）槽位准确率（slot accuracy）：单独比较每个（domain，slot，value），当预测值与真实值匹配时，认为预测正确。</p>
<p>3）推断时间复杂度（inference time complexity, ITC）：ITC的计算方式是完成一次对话状态预测，需要inference多少次。ITC越小越好。</p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>在面向目标（goal-oriented）的对话系统中，信念跟踪器（belief trackers）预测每个对话回合时的槽值对概率分布。以前的神经网络方法已经为领域（ontology）和槽依赖的belief trackers进行了建模，导致领域本体配置缺乏灵活性。</p>
<font color="red">
问题记录：
以往的方法，建模的跟踪器都是领域/槽位依赖的，所以欠缺领域本体设置的灵活性。作者把这些以往的方法统称为slot-dependent methods。这个地方怎么理解，欠缺设置的灵活性？
</font>

<p>在本文中，作者提出了一种新的通用（universal）并可扩展（scalable）的信念跟踪器方法，被称作slot-utterance matching belief tracker（槽-话语匹配的对话状态跟踪器，SUMBT）。模型通过基于上下文语义的注意力机制来学习领域槽类别（domain-slot-types）与对话中出现的槽-值对之间的关系。更进一步的，模型通过一种非参数的方法预测槽-值对的值。</p>
<font color="red">
这里所说的“基于上下文语义的注意力机制”类似就是用BERT作为tokenizer的这个感觉？
</font>

<p>根据作者在两个对话语料库WOZ2.0和MultiWOZ上的实验结果，与槽依赖的方法相比，该模型的性能有所提高，并达到了最先进的joint accuracy。</p>
<font color="red">
还要通过后文的阅读，理解这里作者所说的槽依赖（slot-dependent）的方法到底和作者所提的方法有什么不同。
</font>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>随着会话代理的广泛使用，面向目标的系统越来越受到学术界和工业界的关注。面向目标的对话系统帮助用户实现目标，如在对话结束时预定餐厅或预定航班。随着对话的进行，系统需要更新对话状态的分布，对话状态包括用户的意图、可信息的槽位、和可请求的槽位。这被称作belief tracking（信念跟踪）或者被称作dialogue state tracking（对话状态跟踪, DST）。</p>
<font color="red">
问题记录：
这里对应到数据集上到底在预测什么，除了槽值对外，看起来还有很多需要记录的地方？
</font>

<p>例如，对于给定的域（domain）和槽类型（slot-types），（例：‘restaurant’ domain 和 ‘food’ 槽类型），这个任务估计了在领域本体中<strong>预定义</strong>的，相对应的候选槽值对（slot-value）概率（例：‘Korean’和‘Modern European’）</p>
<p>由于系统使用DST的预测输出，根据对话策略（Policy Learning环节？）选择下一个操作，因此DST的准确性对于提高系统整体性能至关重要。<strong>此外，对话系统应该能够以灵活的方式处理新添加的域和槽，因此开发可伸缩的对话状态跟踪器是不可避免的。</strong> 关于这一点，Chen等人提出一种从意图-话语对中捕捉关系的模型，用于意图扩展。</p>
<font color="red">
问题记录：
这里说以灵活的方式处理新添加的域和槽，这个不应该都是已定义好的，为什么会能增加，作者一直在围绕着可扩展性讲故事。（相对于去雾类的论文中的一些idea，这些想法是否属于在NLP领域中直观的想法）
</font>

<p>传统基于统计方法的belief trackers容易受到词汇和形态变化的影响，因为他们依赖于手动构建的语义词典。随着深度学习方法的兴起，一些neural belief trackers（NBT）被提出，并通过学习单词的语义神经表征来提高性能。然而，可扩展性仍然是一个挑战，先前提出的方法要么对每个域、槽单独建模，要么难以添加本体中未定义的新槽值。</p>
<p>在本文中，我们致力于开发一个“可伸缩”和“通用”的belief tracker，其中只有一个信念跟踪器用于处理任何域和槽类型。为了解决这个问题，我们提出了一种新的方法，称为slot-utterance matching belief tracker（槽-话语匹配的对话状态跟踪器），他是一种与域和槽独立的对话状态跟踪器，其结构如figure 1所示。</p>
<p><img src="/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-27-12-06-39.png"></p>
<p>灵感来自机器阅读理解技术，SUMBT考虑domain-slot type这个组合（例如 ‘restaurant-food’）将其视为一个问题，并在一对用户和系统话语中找到相应的槽值对，假设话语中存在期望的答案。</p>
<p>SUMBT使用最近提出的BERT对系统和用户的话语（utterance）进行编码，BERT提供句子的语境化语义表示。此外，domain-slot-types 和 slot-values也使用BERT进行字面编码</p>
<font color="red">
上边的意思是，这几个地方都会被BERT编码：
[CLS] what type of food would you like? [SEP] a moderately priced modern European food.[SEP]

<p>[CLS] restaurant - food [SEP]</p>
<p>[CLS] modern European [SEP]<br></p></font><p></p>
<p>然后SUMBT根据上下文语义向量，学习与话语词中domain-slot-type相关的“参加方式（the way where to attend）”。该模型基于某些度量以非参数方式预测slot-value的标签，从而使模型体系结构在结构上不依赖于域和slot-types。因此，单个SUMBT可以处理一对domain-slot-type和slot-value，还可以利用多个域和槽之间的共享知识</p>
<font color="red">
或许这篇文章是比较早把BERT结合进来的操作？
</font>

<p>作者在两个目标面向的对话语料库：WOZ2.0 和 MultiWOZ 上通过实验证明该提议模型的有效性。还将定性分析该模型的工作原理。并将其实现公开发布。</p>
<h1 id="SUMBT"><a href="#SUMBT" class="headerlink" title="SUMBT"></a>SUMBT</h1><p>所提出的模型由4部分组成，就像图1中所示的。<br>① BERT encoders，用来对【槽】，【值】，【话语】进行encoding（图中的灰色和蓝色部分）<br>② 一个 slot-用户话语匹配的network（图中的红色部分）<br>③ 一个对话状态跟踪器（图中的橙色部分）<br>④ 一个无参数的鉴别器（discriminator，图中的最上端虚线连接）</p>
<h2 id="Contextual-Semantic-Encoders"><a href="#Contextual-Semantic-Encoders" class="headerlink" title="Contextual Semantic Encoders"></a>Contextual Semantic Encoders</h2><p>对于句子编码器，我们采用了预训练的BERT模型，这是一个双向Transformer编码器的深层堆栈。与普通的词向量相比，这种方式提供了上下文带有语义化的词向量。更进一步的，它提供了词句和句子等词序列的聚合表示，因此我们可以获得由多个词组合的slot-types或slot-values。</p>
<p>这里主要记录下：</p>
<p>slot-values: [[area_slot1, area_slot2, area_slot3…], [food_slot1, …], [price_range_1, …]]</p>
<p>slot-types: [area, food, price range]</p>
<p>经过一系列操作处理后：</p>
<p>y_vt label_token_ids根据v_t slot-values得到: [torch.Size([7, 32]), torch.Size([xx1, 32]), torch.Size([xx2, 32])]，这里xx1，xx2分别代表food和price range的标签数目</p>
<p>q_s slot_token_ids根据s domain-slot-types得到: torch.Size([3, 32])，因为在WOZ这个数据集中只有3个label</p>
<h2 id="Slot-Utterance-Matching"><a href="#Slot-Utterance-Matching" class="headerlink" title="Slot-Utterance Matching"></a>Slot-Utterance Matching</h2><p>为了从话语中检索与domain-slot-type（area，food，price range）对应的相关信息，该模型使用注意力机制。把domain-slot-type经过encoder的encoded vector q^s作为一个query，将其与【每个each】单词位置的上下文语义向量u相匹配，然后计算注意力分数。</p>
<p>这里，作者采用了multi-head attention的注意力机制。多头注意力机制将查询矩阵Q、key矩阵K和value矩阵V映射为不同的线性h投影，然后在这些矩阵上执行缩放点积注意力机制。slot s 和 t处的话语之间的有注意上下文向量hst是：</p>
<p><img src="/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-28-17-32-41.png"></p>
<font color="red">
这里的注意力机制可能需要结合代码和原理详细的学习一下，感觉主要是计算用户每一个词是在哪个domain-slot-type做一个分类的感觉？
</font>

<h2 id="Belief-Tracker-对话状态跟踪器"><a href="#Belief-Tracker-对话状态跟踪器" class="headerlink" title="Belief Tracker 对话状态跟踪器"></a>Belief Tracker 对话状态跟踪器</h2><p>随着对话的进行，每个回合的belief state由之前的对话历史和当前的对话回合决定。这个对话流可以被RNN类的LSTM和GRU，或者Transformer decoders建模（例如：left-to-right uni-directional Transformers）</p>
<p>在本项工作中，上下文向量h_t，还有RNN的上一个state被送入到RNN中，这是用来学习与目标的slot-values相接近的语义向量</p>
<p><img src="/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-28-19-27-17.png"></p>
<font color="red">
等于说每次训练的时候，送入的是当前domain-slot-type和用户utterance的结合，在WOZ数据集上的反应就是，每次训练使用[area, food, price range]这个domain-slot-type结合用户的话术，通过注意力机制实现了用户话语更加关注哪个，然后将这个注意力机制结合之前状态等得到的hidden计算结果与slot-values匹配得到最小的
</font>

<p>作者考虑到BERT是使用layer normalization进行nomal化的，RNN输出的d_t也被送入到一个layer normalizaiton层，来帮助训练训练收敛。</p>
<p><img src="/2021/09/27/research/papers/DST%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-SUMBT/2021-09-28-19-46-31.png"></p>

  	</div>
	  
	  <div class="article-tags tags">
      
        <a href="/tags/NLP/">NLP</a>
      
        <a href="/tags/Dialogue-State-Tracking/">Dialogue State Tracking</a>
      
        <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a>
      
	  </div>
    
		
	
		<div class="art-item-footer">
				
					<span class="art-item-left"><i class="icon icon-chevron-thin-left"></i>prev：<a href="/2021/10/07/research/others/Transformer%E7%A7%AF%E7%B4%AF%E9%98%85%E8%AF%BB/" rel="prev"  title="Transformer积累阅读">
						Transformer积累阅读 
					</a></span>
				
				
					<span class="art-item-right">next：<a href="/2021/09/16/macOS%E5%8F%8ALinux-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7diff/" rel="next"  title="macOS及Linux-命令行工具diff">
						macOS及Linux-命令行工具diff
					</a><i class="icon icon-chevron-thin-right"></i></span>
				
		</div>
	
	</section>
	
</article>
<script>
	window.subData = {
		title: 'DST论文阅读-SUMBT',
		tools: true
	}
</script>

      </div>
      <aside class='l_side'>
        
  <section class='m_widget about'>

<div class='header'>Curious;</div>
<div class='content'>
<div class='desc'>BUPT, Computer Science and Technology, 2021-2024; BJUT, Information Security, 2017-2021</div>
</div>
</section>

  <section class='m_widget links'>
<div class='header'>Links</div>
<div class='content'>
    <ul class="entry">
    
        <li><a class="flat-box" target="_blank" href="https://github.com/yixuan004">
            <div class='name'>yixuan004</div>
        </a></li>
    
    </ul>
</div>
</section>

  <section class='m_widget categories'>
<div class='header'>Categories</div>
<div class='content'>
    
    <ul class="entry">
    
        <li><a class="flat-box" href="/categories/Crsenal/"><div class='name'>Crsenal</div><div class='badget'>16</div></a></li>
    
        <li><a class="flat-box" href="/categories/LeetCode-python/"><div class='name'>LeetCode-python</div><div class='badget'>72</div></a></li>
    
        <li><a class="flat-box" href="/categories/LeetCode-python/LeetCode-%E7%83%AD%E9%A2%98-HOT-100/"><div class='name'>LeetCode-热题 HOT 100</div><div class='badget'>29</div></a></li>
    
        <li><a class="flat-box" href="/categories/LeetCode-python/LeetCode%E5%91%A8%E8%B5%9B/"><div class='name'>LeetCode周赛</div><div class='badget'>26</div></a></li>
    
        <li><a class="flat-box" href="/categories/LeetCode-python/LeetCode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/"><div class='name'>LeetCode每日一题</div><div class='badget'>4</div></a></li>
    
        <li><a class="flat-box" href="/categories/NLP/"><div class='name'>NLP</div><div class='badget'>6</div></a></li>
    
        <li><a class="flat-box" href="/categories/docker/"><div class='name'>docker</div><div class='badget'>4</div></a></li>
    
        <li><a class="flat-box" href="/categories/%E7%AC%94%E8%AF%95%E7%BB%83%E4%B9%A0-python/"><div class='name'>笔试练习-python</div><div class='badget'>1</div></a></li>
    
    </ul>
    
</div>
</section>

  
<div class="m_widget tagcloud">
    <div class="header">Tags</div>
    <div class='content'>
        <a href="/tags/Dataset/" style="font-size: 14px; color: #808080">Dataset</a> <a href="/tags/Dialogue/" style="font-size: 14px; color: #808080">Dialogue</a> <a href="/tags/Dialogue-State-Tracking/" style="font-size: 14.75px; color: #707070">Dialogue State Tracking</a> <a href="/tags/EASY/" style="font-size: 19.63px; color: #080808">EASY</a> <a href="/tags/HARD/" style="font-size: 16.63px; color: #484848">HARD</a> <a href="/tags/LeetCode-python/" style="font-size: 14px; color: #808080">LeetCode-python</a> <a href="/tags/MEDIUM/" style="font-size: 20px; color: #000">MEDIUM</a> <a href="/tags/NLP/" style="font-size: 15.88px; color: #585858">NLP</a> <a href="/tags/TODO%E4%BC%98%E5%8C%96/" style="font-size: 14.38px; color: #787878">TODO优化</a> <a href="/tags/Transformer/" style="font-size: 14px; color: #808080">Transformer</a> <a href="/tags/git/" style="font-size: 14.75px; color: #707070">git</a> <a href="/tags/hexo/" style="font-size: 14.75px; color: #707070">hexo</a> <a href="/tags/macOS%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/" style="font-size: 16.63px; color: #484848">macOS基础操作</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" style="font-size: 14.38px; color: #787878">二分查找</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/" style="font-size: 14.75px; color: #707070">二叉搜索树</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 16.63px; color: #484848">二叉树</a> <a href="/tags/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/" style="font-size: 15.13px; color: #686868">优先队列</a> <a href="/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/" style="font-size: 16.25px; color: #505050">位运算</a> <a href="/tags/%E5%87%A0%E4%BD%95/" style="font-size: 14px; color: #808080">几何</a> <a href="/tags/%E5%88%86%E6%B2%BB/" style="font-size: 14px; color: #808080">分治</a> <a href="/tags/%E5%89%8D%E7%BC%80%E5%92%8C/" style="font-size: 15.13px; color: #686868">前缀和</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 18.13px; color: #282828">动态规划</a> <a href="/tags/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8/" style="font-size: 14px; color: #808080">双向链表</a> <a href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/" style="font-size: 15.88px; color: #585858">双指针</a> <a href="/tags/%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0/" style="font-size: 14px; color: #808080">哈希函数</a> <a href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" style="font-size: 18.5px; color: #202020">哈希表</a> <a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size: 15.5px; color: #606060">回溯</a> <a href="/tags/%E5%A0%86/" style="font-size: 15.13px; color: #686868">堆</a> <a href="/tags/%E5%AD%97%E5%85%B8%E6%A0%91/" style="font-size: 14.75px; color: #707070">字典树</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" style="font-size: 18.88px; color: #181818">字符串</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/" style="font-size: 14px; color: #808080">字符串匹配</a> <a href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" style="font-size: 14px; color: #808080">并查集</a> <a href="/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/" style="font-size: 15.88px; color: #585858">广度优先搜索</a> <a href="/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/" style="font-size: 14px; color: #808080">归并排序</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 17.75px; color: #303030">排序</a> <a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 18.13px; color: #282828">数学</a> <a href="/tags/%E6%95%B0%E7%BB%84/" style="font-size: 19.25px; color: #101010">数组</a> <a href="/tags/%E6%95%B0%E8%AE%BA/" style="font-size: 14px; color: #808080">数论</a> <a href="/tags/%E6%9E%9A%E4%B8%BE/" style="font-size: 15.13px; color: #686868">枚举</a> <a href="/tags/%E6%A0%88/" style="font-size: 15.13px; color: #686868">栈</a> <a href="/tags/%E6%A0%91/" style="font-size: 17.75px; color: #303030">树</a> <a href="/tags/%E6%A8%A1%E6%8B%9F/" style="font-size: 17px; color: #404040">模拟</a> <a href="/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 14px; color: #808080">正则表达式</a> <a href="/tags/%E6%B0%B4%E5%A1%98%E6%8A%BD%E6%A0%B7/" style="font-size: 14px; color: #808080">水塘抽样</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/" style="font-size: 17.38px; color: #383838">深度优先搜索</a> <a href="/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/" style="font-size: 15.5px; color: #606060">滑动窗口</a> <a href="/tags/%E6%BB%9A%E5%8A%A8%E5%93%88%E5%B8%8C/" style="font-size: 14px; color: #808080">滚动哈希</a> <a href="/tags/%E7%8A%B6%E6%80%81%E5%8E%8B%E7%BC%A9/" style="font-size: 14px; color: #808080">状态压缩</a> <a href="/tags/%E7%9F%A9%E9%98%B5/" style="font-size: 16.25px; color: #505050">矩阵</a> <a href="/tags/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/" style="font-size: 14px; color: #808080">组合数学</a> <a href="/tags/%E8%AE%A1%E6%95%B0/" style="font-size: 16.25px; color: #505050">计数</a> <a href="/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2/" style="font-size: 14px; color: #808080">记忆化搜索</a> <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" style="font-size: 14px; color: #808080">论文笔记</a> <a href="/tags/%E8%AE%BE%E8%AE%A1/" style="font-size: 14.75px; color: #707070">设计</a> <a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 17.75px; color: #303030">贪心</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 14px; color: #808080">递归</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15.5px; color: #606060">链表</a> <a href="/tags/%E9%9A%8F%E6%9C%BA%E5%8C%96/" style="font-size: 14px; color: #808080">随机化</a>
    </div>
</div>



      </aside>
      <script>setLoadingBarProgress(60);</script>
    </div>
  </div>
  <footer id="footer" class="clearfix">

	<div class="social-wrapper">
  	
      
        <a href="https://github.com/yixuan004" class="social github"
          target="_blank" rel="external">
          <span class="icon icon-github"></span>
        </a>
      
        <a href="https://twitter.com/kevinsfork" class="social twitter"
          target="_blank" rel="external">
          <span class="icon icon-twitter"></span>
        </a>
      
        <a href="/atom.xml" class="social rss"
          target="_blank" rel="external">
          <span class="icon icon-rss"></span>
        </a>
      
    
  </div>
  
  <div>Theme <a target="_blank" rel="noopener" href='https://github.com/stkevintan/hexo-theme-material-flow' class="codename">MaterialFlow</a> designed by <a href="http://keyin.me/" target="_blank">Kevin Tan</a>.</div>
  
</footer>


  <script>setLoadingBarProgress(80);</script>
  

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src='//cdn.bootcss.com/node-waves/0.7.5/waves.min.js'></script>
<script src="//cdn.bootcss.com/scrollReveal.js/3.3.2/scrollreveal.min.js"></script>

<script src="/js/jquery.fitvids.js"></script>

<script>
	var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
	var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
	var ALGOLIA_API_KEY = "";
	var ALGOLIA_APP_ID = "";
	var ALGOLIA_INDEX_NAME = "";
  var AZURE_SERVICE_NAME = "";
  var AZURE_INDEX_NAME = "";
  var AZURE_QUERY_KEY = "";
  var BAIDU_API_ID = "";
  var SEARCH_SERVICE = "hexo";
  var ROOT = "/"||"/";
  if(!ROOT.endsWith('/'))ROOT += '/';
</script>

<script src="/js/search.js"></script>


<script src="/js/app.js"></script>



  <script>setLoadingBarProgress(100);</script>
</body>
</html>
